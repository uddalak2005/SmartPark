{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51198bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "CSV_PATH = \"/kaggle/input/dataset/observation.csv\"        # change the Path to the dataset CSV file\n",
    "SAVE_FULL = \"/kaggle/working/traffic_transformer_model_2.pth\"   # chenge the Path to the saved full model\n",
    "INPUT_LEN = 72\n",
    "BATCH_SIZE = 128\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "TARGET_PLACE = \"Alipore\"     # change the target location as needed dynamically\n",
    "\n",
    "CONGESTION_THRESHOLDS = {\n",
    "    'LOW': 200 ,   \n",
    "    'MEDIUM': 300 \n",
    "  \n",
    "}\n",
    "\n",
    "def determine_congestion_level(mean_count, thresholds):\n",
    "    \"\"\"Determines the congestion level based on mean car count and predefined thresholds.\"\"\"\n",
    "    if mean_count <= thresholds['LOW']:\n",
    "        return \"Low \"\n",
    "    elif mean_count <= thresholds['MEDIUM']:\n",
    "        return \"Medium \"\n",
    "    else:\n",
    "        return \"High \"\n",
    "\n",
    "class HybridLoss(nn.Module):\n",
    "    \"\"\"alpha * L1 + (1-alpha) * SmoothL1\"\"\"\n",
    "    def __init__(self, alpha=0.6, beta=0.5):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.L1Loss()\n",
    "        self.smooth = nn.SmoothL1Loss(beta=beta)\n",
    "        self.alpha = alpha\n",
    "    def forward(self, pred, target):\n",
    "        return self.alpha * self.l1(pred, target) + (1 - self.alpha) * self.smooth(pred, target)\n",
    "\n",
    "class TransformerForecaster(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=256, num_heads=8, dropout=0.1, seq_len=INPUT_LEN):\n",
    "        super().__init__()\n",
    "        if input_size % num_heads != 0:\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, seq_len, input_size) * 0.01)\n",
    "        self.layer_norm = nn.LayerNorm(input_size)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=input_size,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=hidden_size,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "            activation='gelu'\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=3)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = x + self.pos_embedding[:, :x.size(1), :]\n",
    "        x = self.layer_norm(x)\n",
    "        x = self.transformer(x)\n",
    "        x = x[:, -1, :] \n",
    "        return self.fc(x).squeeze(-1)\n",
    "\n",
    "class TrafficDataset(Dataset):\n",
    "    def __init__(self, data, input_len=INPUT_LEN, feature_dim=None):\n",
    "        self.X, self.y = [], []\n",
    "        for i in range(len(data) - input_len):\n",
    "            self.X.append(data[i:i+input_len, :feature_dim])\n",
    "            self.y.append(data[i+input_len, -1])\n",
    "        self.X = torch.tensor(np.array(self.X), dtype=torch.float32)\n",
    "        self.y = torch.tensor(np.array(self.y), dtype=torch.float32)\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "print(\"Loading and reprocessing data to re-fit scalers...\")\n",
    "try:\n",
    "    df = pd.read_csv(CSV_PATH)\n",
    "except FileNotFoundError:\n",
    "    print(f\"\\n ERROR: File not found at {CSV_PATH}. Please fix the path and try again.\")\n",
    "    df = None \n",
    "\n",
    "if df is not None:\n",
    "    df = df.drop(columns=[\"Datetime\"], errors=\"ignore\")\n",
    "\n",
    "    def extract_hour(timeslot):\n",
    "        if pd.isna(timeslot): return None\n",
    "        try:\n",
    "            start_time = timeslot.split('-')[0].strip()\n",
    "            start_time = re.sub(r'(?i)(AM|PM)', r' \\1', start_time).strip().upper()\n",
    "            return pd.to_datetime(start_time, format='%I:%M %p').hour\n",
    "        except:\n",
    "            try: return pd.to_datetime(start_time, format='%H:%M').hour\n",
    "            except: return None\n",
    "\n",
    "    df['StartHour'] = df['TimeSlot'].apply(extract_hour)\n",
    "    df.dropna(subset=['StartHour'], inplace=True)\n",
    "    df['StartHour'] = df['StartHour'].astype(int)\n",
    "\n",
    "    le_to = LabelEncoder()\n",
    "    df['To_encoded'] = le_to.fit_transform(df['To'])\n",
    "\n",
    "    df['DayOfYear'] = (df['Month'] - 1) * 30 + df['Day']\n",
    "    df['Day_sin'] = np.sin(2 * np.pi * df['DayOfYear'] / 365)\n",
    "    df['Day_cos'] = np.cos(2 * np.pi * df['DayOfYear'] / 365)\n",
    "    df['Hour_sin'] = np.sin(2 * np.pi * df['StartHour'] / 24)\n",
    "    df['Hour_cos'] = np.cos(2 * np.pi * df['StartHour'] / 24)\n",
    "\n",
    "    df = df.sort_values(['To', 'Year', 'Month', 'Day', 'StartHour']).reset_index(drop=True)\n",
    "\n",
    "    for lag in [1, 2, 3, 6, 12, 24]:\n",
    "        df[f'Lag_{lag}'] = df.groupby('To')['CarCount'].shift(lag)\n",
    "\n",
    "    df['MA_3'] = df.groupby('To')['CarCount'].transform(lambda x: x.rolling(3).mean())\n",
    "    df['EMA_5'] = df.groupby('To')['CarCount'].transform(lambda x: x.ewm(span=5, adjust=False).mean())\n",
    "    df['ROLL12_mean'] = df.groupby('To')['CarCount'].transform(lambda x: x.rolling(12).mean())\n",
    "    df['ROLL12_std']  = df.groupby('To')['CarCount'].transform(lambda x: x.rolling(12).std())\n",
    "    df['Diff_1'] = df.groupby('To')['CarCount'].diff(1)\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    feature_cols = [\n",
    "        'StartHour', 'Hour_sin', 'Hour_cos', 'Day_sin', 'Day_cos',\n",
    "        'To_encoded', 'MA_3', 'EMA_5', 'ROLL12_mean', 'ROLL12_std', 'Diff_1'\n",
    "    ] + [f'Lag_{i}' for i in [1, 2, 3, 6, 12, 24]]\n",
    "\n",
    "    scaler_X = MinMaxScaler()\n",
    "    df[feature_cols] = scaler_X.fit_transform(df[feature_cols])\n",
    "\n",
    "    scaler_y = MinMaxScaler()\n",
    "    df['y_scaled'] = scaler_y.fit_transform(df[['CarCount']])\n",
    "\n",
    "    df_target = df[df['To'] == TARGET_PLACE].copy()\n",
    "    if df_target.empty:\n",
    "        raise ValueError(f\"No data found for the target location: {TARGET_PLACE}\")\n",
    "        \n",
    "    values = df_target[feature_cols + ['y_scaled']].values\n",
    "    feature_dim = len(feature_cols)\n",
    "\n",
    "    train_size = int(len(values) * 0.8) \n",
    "    test_data = values[train_size:]\n",
    "\n",
    "    if len(test_data) < INPUT_LEN + 200:\n",
    "        print(f\" Warning: Not enough data for {TARGET_PLACE} to get 200 predictions with an input length of {INPUT_LEN}. Using all available test data.\")\n",
    "\n",
    "    test_dataset  = TrafficDataset(test_data, input_len=INPUT_LEN, feature_dim=feature_dim)\n",
    "    test_loader  = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    print(f\"Test samples re-created for {TARGET_PLACE}: {len(test_dataset)}\")\n",
    "\n",
    "model_loaded = None\n",
    "if df is not None:\n",
    "    try:\n",
    "        print(f\"\\nAttempting to load full model from {SAVE_FULL} onto {DEVICE}...\")\n",
    "        model_loaded = torch.load(\n",
    "            SAVE_FULL, \n",
    "            map_location=DEVICE,\n",
    "            weights_only=False \n",
    "        )\n",
    "        model_loaded.eval()\n",
    "        print(f\" Successfully loaded full model from {SAVE_FULL} onto {DEVICE}.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n Final failure to load full model. Error: {e}\")\n",
    "        model_loaded = None\n",
    "\n",
    "if model_loaded:\n",
    "    preds_scaled_all, actuals_scaled_all = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch = X_batch.to(DEVICE)\n",
    "            y_pred = model_loaded(X_batch).view(-1).cpu().numpy()\n",
    "            preds_scaled_all.extend(y_pred)\n",
    "            actuals_scaled_all.extend(y_batch.view(-1).cpu().numpy())\n",
    "            \n",
    "            if len(preds_scaled_all) >= 200:\n",
    "                break \n",
    "\n",
    "    preds_all = scaler_y.inverse_transform(np.array(preds_scaled_all).reshape(-1,1)).flatten()\n",
    "    actuals_all = scaler_y.inverse_transform(np.array(actuals_scaled_all).reshape(-1,1)).flatten()\n",
    "\n",
    "    N_SAMPLES = min(200, len(preds_all))\n",
    "    preds_200 = preds_all[:N_SAMPLES]\n",
    "    actuals_200 = actuals_all[:N_SAMPLES]\n",
    "\n",
    "    mae_200 = mean_absolute_error(actuals_200, preds_200)\n",
    "    mean_predicted_car_count = np.mean(preds_200)\n",
    "    congestion_level = determine_congestion_level(mean_predicted_car_count, CONGESTION_THRESHOLDS)\n",
    " \n",
    "    print(f\"\\nPrediction Results for the first {N_SAMPLES} Test Samples at {TARGET_PLACE}:\")\n",
    "    print(f\"Mean Absolute Error (MAE) for the subset: {mae_200:.3f}\")\n",
    "    print(f\"Mean Predicted Car Count for the subset: {mean_predicted_car_count:.2f}\")\n",
    "    print(f\"Inferred Congestion Level: {congestion_level}\") \n",
    "\n",
    "    #plt.figure(figsize=(12, 6))\n",
    "    #plt.plot(actuals_200, label='Actual Car Count', linewidth=2)\n",
    "    #plt.plot(preds_200, label='Predicted Car Count', linestyle='--')\n",
    "    #plt.title(f'Traffic Forecast for {TARGET_PLACE} (Congestion: {congestion_level})') \n",
    "    #plt.xlabel(f'Time Index (Offset from Start of {TARGET_PLACE} Test Set)')\n",
    "    #plt.ylabel('Car Count')\n",
    "    #plt.legend()\n",
    "    #plt.grid(True)\n",
    "    #plt.tight_layout()\n",
    "    #plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
